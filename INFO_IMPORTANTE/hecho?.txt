Here's a summary of what we've done:

1. Created a Telegram scraper that:
   - Connects to Telegram using the API
   - Scrapes messages from specified channels
   - Saves messages in parquet files with format `{date}_telegram.parquet`
   - Stores them in the project's `/data/messages` directory

2. Fixed several issues:
   - Corrected the import path for the info.py credentials
   - Fixed the DATA_DIR path to correctly point to the root data directory
   - Added rate limit handling for Telegram API requests

3. Integration with main system:
   - The Telegram data is now saved in the same format as El Toque data
   - The parquet files are compatible with the existing analytics pipeline
   - No modifications to the analytics code were needed since it already handles all .parquet files in the messages directory

The system now:
- Scrapes data from both sources (El Toque and Telegram)
- Processes all messages through the same analytics pipeline
- Generates metrics and visualizations for all data

Next steps could be:
1. Running the analytics pipeline to process the new Telegram data
2. Checking the dashboard to see the analyzed data
3. Potentially modifying the dashboard to distinguish between data sources

Would you like to proceed with any of these next steps?